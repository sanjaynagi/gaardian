{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1af42",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "contig = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.auth\n",
    "import gcsfs\n",
    "\n",
    "credentials, project_id = google.auth.default()\n",
    "print(credentials)\n",
    "print(project_id)\n",
    "\n",
    "gcs = gcsfs.GCSFileSystem(\n",
    "      token=credentials,\n",
    "      project=project_id, \n",
    "      cache_timeout=0, \n",
    "      block_size=2**18,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aec5ef-e85f-48e4-8478-6f8c62d3cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ancIBD\n",
    "import allel\n",
    "import malariagen_data\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "@njit()\n",
    "def convert_genotypes_to_probs(genotypes, error_rate=0.01):\n",
    "    snps, samples, _ = genotypes.shape\n",
    "    probs = np.zeros((snps, samples, 3), dtype=np.float64)\n",
    "    \n",
    "    for i in range(snps):\n",
    "        for j in range(samples):\n",
    "            allele1, allele2 = genotypes[i, j]\n",
    "            \n",
    "            if allele1 == 0 and allele2 == 0:\n",
    "                probs[i, j] = [1 - error_rate, error_rate / 2, error_rate / 2]\n",
    "            elif allele1 == 0 and allele2 == 1:\n",
    "                probs[i, j] = [error_rate / 2, 1 - error_rate, error_rate / 2]\n",
    "            elif allele1 == 1 and allele2 == 0:\n",
    "                probs[i, j] = [error_rate / 2, 1 - error_rate, error_rate / 2]\n",
    "            else:  # allele1 == 1 and allele2 == 1\n",
    "                probs[i, j] = [error_rate / 2, error_rate / 2, 1 - error_rate]\n",
    "    \n",
    "    return probs\n",
    "\n",
    "def read_ag_gmap(contig):\n",
    "    if contig in {\"2RL\", \"3RL\"}:\n",
    "        chrom = contig[0]\n",
    "        contig_r, contig_l = f\"{chrom}R\", f\"{chrom}L\"\n",
    "        df_r = read_ag_gmap(contig_r)\n",
    "        df_l = read_ag_gmap(contig_l)\n",
    "        max_ppos = df_r[\"pposition\"].iloc[-1]\n",
    "        max_gpos = df_r[\"gposition\"].iloc[-1]\n",
    "        df_l = df_l.iloc[1:]\n",
    "        df_l[\"pposition\"] += max_ppos\n",
    "        df_l[\"gposition\"] += max_gpos\n",
    "        df = pd.concat([df_r, df_l], axis=0, ignore_index=True)\n",
    "    else:\n",
    "        df = pd.read_csv(gmap_dict[contig], sep=\"\\t\")\n",
    "    return df\n",
    "    \n",
    "def ag_gmap(contig):\n",
    "    ag3 = malariagen_data.Ag3()\n",
    "        \n",
    "    # read in the genetic map file\n",
    "    df_gmap = read_ag_gmap(contig)\n",
    "\n",
    "    # set up an array of per-base recombination rate values\n",
    "    rr = np.zeros(len(ag3.genome_sequence(contig)), dtype=\"f8\")\n",
    "\n",
    "    # fill in the recombination rate values from the genetic map file\n",
    "    for row, next_row in zip(\n",
    "        itertools.islice(df_gmap.itertuples(), 0, len(df_gmap)-1), \n",
    "        itertools.islice(df_gmap.itertuples(), 1, None)):\n",
    "        \n",
    "        # N.B., the genetic map file is in units of cM / Mbp\n",
    "        # we multiple by 1e-6 to convert to cM / bp\n",
    "        rr[row.pposition-1:next_row.pposition] = row.rrate * 1e-6\n",
    "    \n",
    "    # compute mapping from physical to genetic position\n",
    "    gmap = np.cumsum(rr)\n",
    "        \n",
    "    return gmap\n",
    "    \n",
    "def ag_p2g(contig, ppos):\n",
    "    \"\"\"Convert physical position (bp) to genetic position (M).\"\"\"\n",
    "    gmap = ag_gmap(contig)\n",
    "    gpos = gmap[ppos - 1]\n",
    "    return gpos / 100 # morgans not centimorgans \n",
    "\n",
    "\n",
    "gmap_dict = {contig : f\"https://raw.githubusercontent.com/anopheles-genomic-surveillance/selection-atlas/main/workflow/notebooks/ag_{contig}.gmap\"\n",
    "            for contig in ['2L', '2R', '3L', '3R', 'X']\n",
    "}\n",
    "\n",
    "\n",
    "def prepare_ancIBD_input(contig, sample_sets, sample_query, cohort_size=None):\n",
    "    # load haplotypes\n",
    "    ds_haps = ag3.haplotypes(region=contig, sample_sets=sample_sets, sample_query=sample_query, cohort_size=cohort_size)\n",
    "    \n",
    "    # load arrays\n",
    "    gt = allel.GenotypeArray(ds_haps['call_genotype'].values)\n",
    "    pos = ds_haps['variant_position'].values\n",
    "    samples = ds_haps['sample_id'].values\n",
    "\n",
    "    # find segregating sites\n",
    "    seg_ = gt.count_alleles().is_segregating()\n",
    "    gt = gt.compress(seg_, axis=0)\n",
    "    pos = pos[seg_]\n",
    "\n",
    "    # find the alternate allele frequency\n",
    "    frqs = gt.count_alleles().to_frequencies()\n",
    "    alt_frqs = frqs[:, 1]\n",
    "    \n",
    "    # convert GTs to genotype probabilities\n",
    "    gp = convert_genotypes_to_probs(gt.values)\n",
    "\n",
    "    # prepare input dictionary\n",
    "    input_dict = {\n",
    "        'calldata/GT':gt.values,\n",
    "        'calldata/GP':gp,\n",
    "        'calldata/AF': alt_frqs,\n",
    "        'variants/POS':pos,\n",
    "        'variants/MAP':ag_p2g(contig=contig, ppos=pos),\n",
    "        'samples':samples\n",
    "    }\n",
    "    \n",
    "    return input_dict\n",
    "\n",
    "# vectorized haversine function\n",
    "def haversine(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=6371):\n",
    "    \"\"\"\n",
    "    slightly modified version: of http://stackoverflow.com/a/29546836/2901002\n",
    "\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees or in radians)\n",
    "\n",
    "    All (lat, lon) coordinates must have numeric dtypes and be of equal length.\n",
    "\n",
    "    \"\"\"\n",
    "    if to_radians:\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    a = np.sin((lat2-lat1)/2.0)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n",
    "\n",
    "    return earth_radius * 2 * np.arcsin(np.sqrt(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336fb40-9398-4e69-978c-fad1440ae1c9",
   "metadata": {},
   "source": [
    "### I need to prepare a dict containing multiple arrays for a given contig:\n",
    "\n",
    "- calldata/GT\n",
    "- calldata/GP\n",
    "- genomic positions\n",
    "- linkage map\n",
    "- samples\n",
    "\n",
    "Lets try and create these directly from malariagen_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f195d-48c2-4ec2-ba9d-7f270f6b23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag3 = malariagen_data.Ag3(results_cache=\"../results_cache/\")\n",
    "\n",
    "sample_sets = \"1244-VO-GH-YAWSON-VMF00149\"\n",
    "sample_query = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7dda80-63d2-4f3a-878b-65aa85492de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = prepare_ancIBD_input(contig=contig, sample_sets=sample_sets, sample_query=sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75abcb-4cad-4c83-bf8f-8ef93b5a1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ancIBD.run import hapBLOCK_chroms\n",
    "\n",
    "df_ibd = hapBLOCK_chroms(folder_in=input_dict,\n",
    "                         iids=input_dict['samples'], \n",
    "                         run_iids=[],\n",
    "                         ch=contig, \n",
    "                         folder_out=\"results/ancIBD/\",\n",
    "                         output=False, \n",
    "                         prefix_out='', \n",
    "                         logfile=False,\n",
    "                         l_model='dict',\n",
    "                         e_model='haploid_gl2', \n",
    "                         h_model='FiveStateScaled', \n",
    "                         t_model='standard',\n",
    "                         p_col='calldata/AF',\n",
    "                         ibd_in=1,\n",
    "                         ibd_out=10, \n",
    "                         ibd_jump=400,\n",
    "                         min_cm=1,\n",
    "                         cutoff_post=0.99,\n",
    "                         max_gap=0.0075)\n",
    "\n",
    "df_ibd = df_ibd.assign(size=lambda x: x.EndBP - x.StartBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7357f-d1a5-48f0-931b-99248cb3df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = ag3.sample_metadata(sample_sets=sample_sets, sample_query=sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06634127-ffb6-4e4d-a923-6edf002bfdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = df_samples[['sample_id', 'location', 'latitude', 'longitude']]#''.groupby('location').agg({'latitude':'mean', 'longitude':'mean'}).reset_index()\n",
    "df_loc = df_loc.assign(location=df_loc.location.str.split(\".\").str.get(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461f003-8736-4631-8263-c32a1e7696a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ibd.to_csv(\"df_ibd.csv\")\n",
    "df_ibd = pd.read_csv(\"../../results/ancIBD/chX.tsv\", sep=\"\\t\", index_col=0)\n",
    "df_ibd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibd = df_ibd.assign(size=lambda x: x.EndBP - x.StartBP,\n",
    "                       cm=lambda x: x.lengthM * 100,\n",
    "                       ).sort_values(\"size\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3cb9a-7103-4cc3-a5fa-714df5342258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibd = df_ibd.query(\"cm > 12\")\n",
    "print(df_ibd.shape)\n",
    "\n",
    "\n",
    "n_segments = df_ibd.groupby(['iid1', 'iid2']).size()\n",
    "\n",
    "df_ibd_agg = df_ibd.groupby(['iid1', 'iid2']).agg({'cm':'sum'}).reset_index()\n",
    "df_ibd_agg.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd155fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = df_samples.assign(location=df_samples.location.str.split(\".\").str.get(0))\n",
    "\n",
    "# check are iid1 and iid2 always the same location in df_samples\n",
    "loc1s = []\n",
    "loc2s = []\n",
    "dists = []\n",
    "for i, row in tqdm(df_ibd_agg.iterrows()):\n",
    "    loc1 = df_samples[df_samples.sample_id == row.iid1].location.values[0]\n",
    "    loc2 = df_samples[df_samples.sample_id == row.iid2].location.values[0]\n",
    "    loc1s.append(loc1)\n",
    "    loc2s.append(loc2)\n",
    "\n",
    "    # calc geographic distance\n",
    "    lat1, lon1 = df_samples[df_samples.sample_id == row.iid1][['latitude', 'longitude']].values[0]\n",
    "    lat2, lon2 = df_samples[df_samples.sample_id == row.iid2][['latitude', 'longitude']].values[0]\n",
    "    dist = haversine(lat1, lon1, lat2, lon2)\n",
    "    dists.append(dist)\n",
    "\n",
    "df_ibd_agg = df_ibd_agg.assign(loc1=loc1s, loc2=loc2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11179b0-40f1-45e7-8b40-934239b58f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter_3d(\n",
    "    df_ibd_agg.assign(geographic_distance=dists), \n",
    "    x='geographic_distance', \n",
    "    y='cm',\n",
    "    z=n_segments, \n",
    "    template='simple_white', \n",
    "    hover_data=['iid1', 'iid2']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82402eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bokeh.io import output_notebook # enables plot interface in J notebook\n",
    "# output_notebook(hide_banner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61784e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_ibd_segments_contig(\n",
    "#     self,\n",
    "#     df,\n",
    "#     contig, \n",
    "#     filter_expr=pl.col('n_snps') > 10_000,\n",
    "#     show=False,\n",
    "#     width=None,\n",
    "#     height=400\n",
    "# ):\n",
    "#     from itertools import combinations\n",
    "#     import bokeh.plotting as bkplt\n",
    "#     import bokeh.models as bkmod\n",
    "#     import bokeh.layouts as bklay\n",
    "    \n",
    "#     df = df.filter(pl.col('contig') == contig).filter(filter_expr)\n",
    "        \n",
    "#     print(\"finding levels\")\n",
    "#     max_inds = df['idx1'].max() + 1\n",
    "#     level_df = pl.DataFrame(list(combinations(range(max_inds), 2))).transpose()\n",
    "#     level_df = level_df.with_columns(pl.lit(np.linspace(0, 1, len(list(combinations(range(max_inds), 2))))).alias(\"level\"))\n",
    "#     level_df = level_df.rename({'column_0':'idx1', 'column_1':'idx2'}).with_columns(pl.col(\"idx1\").cast(pl.Int32),\n",
    "#                                                                                    pl.col(\"idx2\").cast(pl.Int32))\n",
    "#     df = df.join(level_df, on=['idx1', 'idx2'])\n",
    "    \n",
    "# #     print(\"colour mapping\")\n",
    "# #     colour_mapping = {'half-ibd':'gray', \n",
    "# #                       'full-ibd':'blue'}\n",
    "# #     colour = df['ibd_type'].apply(lambda x: colour_mapping[x])\n",
    "\n",
    "#     source = bkmod.ColumnDataSource(data={\n",
    "#         'index1': df['idx1'].to_numpy(),\n",
    "#         'index2': df['idx2'].to_numpy(),\n",
    "#          'sample_id1':df['sample_id1'].to_numpy(),\n",
    "#          'sample_id2':df['sample_id2'].to_numpy(),\n",
    "#         'chromosome': df['contig'].to_numpy(),\n",
    "#         'start': df['start'].to_numpy(),\n",
    "#         'end': df['end'].to_numpy(),\n",
    "#         'bottoms':df['level'].to_numpy(),\n",
    "#         'tops': df['level'].to_numpy()+0.0001,\n",
    "# #         'colour': colour.to_numpy()\n",
    "#     })\n",
    "\n",
    "#     hover = bkmod.HoverTool(tooltips=[\n",
    "#             (\"index1\", '@index1'),\n",
    "#             (\"index2\", '@index2'),\n",
    "#              (\"sample_id1\", '@sample_id1'),\n",
    "#              (\"sample_id2\", '@sample_id2'),\n",
    "#             (\"segment span\", \"@start{,} - @end{,}\"),\n",
    "#         ])\n",
    "        \n",
    "#     print(\"making figure\")\n",
    "#     if not width:\n",
    "#         width = int(self.genome_sequence(contig).shape[0]/200000)\n",
    "#     fig1 = bkplt.figure(title=contig,\n",
    "#                         width=width,\n",
    "#                         height=500, \n",
    "#                         tools=\"tap,box_zoom,xpan,xzoom_in,xzoom_out,xwheel_zoom,reset\".split() + [hover],\n",
    "#                         toolbar_location='above', active_drag='xpan', active_scroll='xwheel_zoom',\n",
    "#                         output_backend=\"webgl\")\n",
    "\n",
    "#     glyph = bkmod.Quad(left='start', right='end', bottom='bottoms', top='tops', line_color=\"grey\", line_alpha=.8, line_width=1)\n",
    "#     fig1.add_glyph(source, glyph)\n",
    "\n",
    "#     fig1.x_range = bkmod.Range1d(0, self.genome_sequence(contig).shape[0], bounds='auto')\n",
    "#     fig1.y_range = bkmod.Range1d(0, 1, bounds='auto')\n",
    "#     fig1.x_range.max_interval = self.genome_sequence(contig).shape[0]\n",
    "#     fig1.yaxis.visible = False\n",
    "#     fig1.ygrid.visible = False\n",
    "#     _bokeh_style_genome_xaxis(fig1, contig)\n",
    "    \n",
    "#     if show:\n",
    "#         bkplt.show(fig1)\n",
    "    \n",
    "#     return fig1\n",
    "\n",
    "# def plot_ibd_segments(\n",
    "#         self,\n",
    "#         df, \n",
    "#         out_dir,\n",
    "#         cohort_id,\n",
    "#         contigs=('2RL', '3RL', 'X'),\n",
    "#         filter_expr=pl.col('n_snps') > 10_000,\n",
    "#         show=True,\n",
    "#         title=None,\n",
    "#     ):\n",
    "#     import bokeh.models as bkmod\n",
    "#     import bokeh.layouts as bklay\n",
    "#     import bokeh.plotting as bkplt\n",
    "    \n",
    "#     figs = [\n",
    "#             plot_ibd_segments_contig(\n",
    "#                 self=self,\n",
    "#                 df=df,\n",
    "#                 contig=contig,\n",
    "#                 filter_expr=filter_expr,\n",
    "#                 ) \n",
    "#             for contig in tqdm(contigs)\n",
    "#             ]\n",
    "    \n",
    "#     if out_dir:\n",
    "#         bkplt.output_file(filename=out_dir + cohort_id + \"_segments.html\", title=title)\n",
    "\n",
    "#     fig = bklay.gridplot(\n",
    "#         figs,\n",
    "#         ncols=len(contigs),\n",
    "#         toolbar_location=\"above\",\n",
    "#         merge_tools=True,\n",
    "#     ) \n",
    "    \n",
    "#     if out_dir:\n",
    "#         bkplt.save(fig)\n",
    "    \n",
    "#     if show:\n",
    "#         bkplt.show(fig)\n",
    "    \n",
    "#     return fig\n",
    "    \n",
    "# def _bokeh_style_genome_xaxis(fig, contig):\n",
    "#     import bokeh.models as bkmod\n",
    "#     \"\"\"Standard styling for X axis of genome plots.\"\"\"\n",
    "#     fig.xaxis.axis_label = f\"Contig {contig} position (bp)\"\n",
    "#     fig.xaxis.ticker = bkmod.AdaptiveTicker(min_interval=1)\n",
    "#     fig.xaxis.minor_tick_line_color = None\n",
    "#     fig.xaxis[0].formatter = bkmod.NumeralTickFormatter(format=\"0,0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
